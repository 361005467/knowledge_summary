# 索引

聚簇索引：叶子点是数据

非聚簇索引：叶子点是主键

innodb 主键索引是聚集索引，（二级索引）辅助索引是非聚簇索引

为什么辅助索引叶节点是主键而不是行指针？数据插入时，数据移动，行指针会变，主键不会，不需要大幅度更新辅助索引

自增 id 做主键，插入的时候直接放在最后。否则插在中间引起数据重排

# b+树

b+树叶子点保存所有数据，b 树在中间节点保存数据
b+树优点

- b+树的中间节点不保存数据，所以磁盘页能容纳更多节点元素
- 对于范围查找来说，b+树只需遍历叶子节点链表

# mysql

ACID

- a：原子性，全部成功或失败
- c： 数据一致性
- i 事务之间的隔离性
- d commited 后必须持久化

隔离级别

- read uncommitted: 未 commit 的数据也能读
  - 产生脏读：读了未 commit 并且 rollback 的数据
- read commited: commit 过的数据就能读.每次读都生成快照
  - 产生不可重复读：读同一条数据两次结果不一样
  - 产生幻读： select 全表，第二次比第一次多了数据
- repeateable read: 开始事务时，生成快照，数据都从快照读
- serailization： 加锁

MVCC：通过数据版本来处理并发场景。 每条数据都会有历史版本。

快照生成: 查版本链，找自己版本小但最大的版本

- read commited： 每次 select 都取快照，
- repeateable read： 开启事务的时候取快照
- 快照读，读快照的数据
  - 简单的 select 操作(不包括 select ... lock in share mode, select ... for update)
- 当前读：读最新，加锁
  - select ... lock in share mode，select ... for update insert，update，delete

锁

- 行锁：innodb 上，设置索引的字段可以加行锁，
- 表锁：没索引就锁全表
- 悲观锁
  - select for update
  - 颗粒度大，性能弱
- 乐观锁
  - 增加版本字段，写之前先比较
  - 只适合并发少的场景

数据划分

- 分表
  - 单数据库建多张表，要考虑查询排序问题
  - 尽量让查询落在单表
- mysql paritition 分区
  - 对应用层来说是一张表，mysql 自动划分存储。
- 分库
  - 分到多个数据库
- 分片 sharding
  - 多主机保存数据，要考虑事务场景
  - mongo 内置 sharding，会自动分布式查询， mysql 需要应用层实现
- 副本集 replica set 数据冗余

## 主从复制

复制方法：master binlog 记录操作，从节点通过网络调用读取 binlog 放到 relay log， 然后根据 relay log 复制

- 同步复制 所有从节点写入成功便返回
- 异步复制 不需要从节点确认，直接返回
- 半同步复制 一个从节点成功写入 relay，即刻返回

## 一致性

- 强一致性：每次读都能读最新
- 最终一致性：最后都能读最新
- 开源 redis 和 mysql 不保证强一致性

# redis

基本结构

- 字符串
- 哈希，开链法，桶+链表
- sorted set：跳表，范围查询 o（logn）

rehash

- 重新建桶，把链表重新划分到不同的桶
- 时机：1.数据操作时，移动对应的桶 2.定时任务

过期删除 timeout

- 数据结构：过期字典
- 被动删除：当读/写一个已经过期的 key 时，会触发惰性删除策略，直接删除掉这个过期 key
- 主动删除：定期主动淘汰一批已过期的 key

数据淘汰

- 多种淘汰策略，例如 lru，哈希+双向链表

持久化

- aof：以日志的形式记录服务器所处理的每一个写操作
  - 重写：当文件太大时，根据数据重写操作记录
- rdb： fork 一个子进程，保存整个数据集

分布式部署

- 主从 1 主多从
- 哨兵 1 主多从+监控，切换故障 master
- 集群 多主多从
- 故障会导致数据丢失，主从不一致

数据划分

- 哈希槽： 分成 2^14 个槽，每个 master 分配一定数量的槽，路由表存在客户端
- 一致性哈希：机器 ip 求 mod，key 求模后找最近的机器 ip mod
